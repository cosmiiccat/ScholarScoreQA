# ScholarScoreQA
# K-Span ScholarQA Official implementation of the paper *“K-Span Select and Multi-Dimensional Judging for Reliable Scholarly Question Answering”* (IEEE JCDL 2025).   This repository implements K-Span Select for span-level retrieval and ScholarScore for reliable, style-aware scholarly question answering.

Scholarly question answering (QA) over long docu- ments is challenging because relevant evidence is scattered, and language models struggle with irrelevant context. We present a retrieval-augmented framework that integrates span-level re- trieval, prompting strategies, and multi-dimensional evaluation to improve reliability in scholarly QA. Our method introduces K-Span Select, which condenses documents into query-relevant spans while preserving over 87% of gold evidence and reducing context size by 91%. Candidate answers are then generated using diverse prompting strategies, including zero-shot, few-shot, chain- of-thought, and meta prompting. To filter and adapt responses, we design two modules: the Language Judge, which scores answers on correctness, groundedness, fluency, and format, and the Tone Judge, which tailors answers to academic, technical, or layman styles. The final answer is selected using ScholarScore, a composite of language and tone quality. Experiments on QASPER and QASA show that our system consistently outperforms com- petitive methods, with ROUGE-1 improving from 0.26 to 0.30 and Span-F1 by +3.4 points. These results highlight the effectiveness of compact retrieval and multi-dimensional judging in digital library QA.
